---
date: 2017-07-06 21:30:00
status: public
title: 似然与极大似然估计
tags: 
 - 机器学习
categories:
 - machine learning
---
## 概要
本文先会介绍似然的概念，似然与概率的区别，然后介绍参数估计的方法——极大似然估计。

## 似然
在统计学中，似然函数（likelihood function，通常简写为likelihood，似然）是一个非常重要的内容，在非正式场合似然和概率（Probability）几乎是一对同义词，但是在统计学中似然和概率却是两个不同的概念。

**概率是在特定环境下某件事情发生的可能性**，也就是结果没有产生之前依据环境所对应的参数来预测某件事情发生的可能性，比如抛硬币，抛之前我们不知道最后是哪一面朝上，但是根据硬币的性质我们可以推测任何一面朝上的可能性均为50%，这个概率只有在抛硬币之前才是有意义的，抛完硬币后的结果便是确定的；

而似然刚好相反，是在**确定的结果下去推测产生这个结果的可能环境（参数）**，还是抛硬币的例子，假设我们随机抛掷一枚硬币1,000次，结果500次人头朝上，500次数字朝上（实际情况一般不会这么理想，这里只是举个例子），我们很容易判断这是一枚标准的硬币，两面朝上的概率均为50%，这个过程就是我们根据结果来判断这个事情本身的性质（参数），也就是似然。

## 极大似然估计
似大似然估计解决的问题是，最大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。似大似然估计经常在机器学习方法中作为一种学习策略。

似然函数的最大值意味着什么？让我们回到概率和似然的定义，概率描述的是在一定条件下某个事件发生的可能性，概率越大说明这件事情越可能会发生；而似然描述的是结果已知的情况下，该事件在不同条件下发生的可能性，似然函数的值越大说明该事件在对应的条件下发生的可能性越大。

也就是说**似然函数取得最大值表示相应的参数能够使得统计模型最为合理。**

考虑一个抛硬币的例子。假设这个硬币正面跟反面轻重不同。我们把这个硬币抛80次（即，我们获取一个采样$x_1=H,x_2=T,.....x_{80}$并把正面的次数记下来，正面记为H，反面记为T）。并把抛出一个正面的概率记为p，抛出一个反面的概率记为1-p（因此，这里的  p即相当于上边的 $\theta$ ）。
假设我们抛出了49个正面，31个反面，即49次H，31次T。假设这个硬币是我们从一个装了三个硬币的盒子里头取出的。这三个硬币抛出正面的概率分别为p=1/3,  p=1/2,p=2/3.这些硬币没有标记，所以我们无法知道哪个是哪个。
使用最大似然估计，通过这些试验数据（即采样数据），我们可以计算出哪个硬币的可能性最大。这个似然函数取以下三个值中的一个：
$$
P(H=49,T=31 | p=1/3) = (1/3)^{49}(1-1/3) ^{31}= 0.000 \\
P(H=49,T=31 | p=1/2) = (1/2)^{49}(1-1/2)^{31} = 0.012 \\
P(H=49,T=31 | p=2/3) = (2/3)^{49}(1-2/3)^{31} = 0.054 \\
$$
我们可以看到当p=2/3时，似然函数取得最大值。这就是  p的最大似然估计。

但在机器学习中我们要估计的并不是离散的情况，因此最大似然估计的一般求解过程是：
1. 写出似然函数；
2. 对似然函数取对数，并整理，也就对数似然函数；
3. 求导数，解似然方程，也就是取极值；

- - - -
参考：
https://zhuanlan.zhihu.com/p/22092462
https://zh.wikipedia.org/wiki/似然函数
https://zh.wikipedia.org/wiki/最大似然估计