---
date: 2019-04-14 09:03:00
status: public
tags: 
 - 机器学习
title: GBDT 解理
categories:
 - machine learning
---
GBDT 全称是 Gradient Boosting Decision Tree，我们从分别这几个词来理解 GBDT;


### Boosting
GBDT 整体框架属于Boosting算法。Boosting方法是一种常用的统计学习方法，应用广泛有效。分类问题中，它通过**改变训练样本的权重**，学习多个**弱分类器**，并将这些分类器进行线性组合，提高分类性能。这里只对Boosting 这做简单说明。


### Decision Tree
在 GBDT中学习的弱分类器就是决策树，具体来说是回归树并不是分类树，这里也不展开说明。


### Gradient 
GBDT中改变训练样本的权重的方式是Gradient，使用 GBDT 来做回归任务时，通过推导Gradient=残差


### 回归问题的GBDT的学习过程
通俗点来讲，GBDT 是由一排回归树组成的，每一颗决策树学习目标是拟合前一颗树的Gradient或残差。

1. 初始化$f_0(x)=0$
2. 对$m = 1,2、、、M$
   1. 计算残差
   $$
    r_{mi} = y_i-f_{m-1}(x), i=1,2、、、N
   $$
   2. 拟合残差$r_{mi}$学习一棵回归树，得到$h_m(x)$
   3. 更新$f_m(x) = f_{m-1} + h_m(x)$
3. 得到回归问题的提升树


---
参考：  
[https://blog.csdn.net/zpalyq110/article/details/79527653](https://blog.csdn.net/zpalyq110/article/details/79527653)
[https://blog.csdn.net/u012422446/article/details/51506392](https://blog.csdn.net/u012422446/article/details/51506392)
[https://blog.csdn.net/anshuai_aw1/article/details/83040541](https://blog.csdn.net/anshuai_aw1/article/details/83040541)  
[机器学习算法GBDT的面试要点总结-上篇](https://www.cnblogs.com/ModifyRong/p/7744987.html)  
[GBDT算法整理](https://blog.csdn.net/davidie/article/details/50897278)
[https://www.msra.cn/zh-cn/news/features/lightgbm-20170105](https://www.msra.cn/zh-cn/news/features/lightgbm-20170105)