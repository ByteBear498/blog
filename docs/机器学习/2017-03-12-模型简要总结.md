---
date: 2017-03-12 11:03:00
status: public
title: 模型简要总结
categories:
 - machine learning
---

# 模型简要总结
## 决策树
### 介绍
决策树是一种分类和回归方法。下面主要介绍分类部分。决策树模型呈树状结构，在分类问题中，表示基于特征对实例进行分类的过程。它也可以认为是if-then规则的集合。

### 模型的学习
决策树的学习本质上是从训练数据中归纳出一组分类规则。能对训练数据进行正确分类的决策树可能有多个，我们需要的是一个与训练数据矛盾较少，同时具有很好的泛化能力。决策树学习通常需要3个步骤：
1.  特征选择

+ 信息增益：特征对训练集的信息增益，等价于互信息。信息增益大的特征具有更强的分类能力。
$$
g(D,A)=H(D)-H(D \mid A)
$$
+ 信息增益比：其信息增益与训练数据集关于特征A的值的熵$H_A(D)$之比
$$
g_R(D,A)=\frac{g(D,A)}{H_A(D)}
$$

2.  决策树生成
3.  决策树的剪枝


### 优缺点：


## logstic回归

## 最大熵

## 支持向量机

## 隐马尔可夫模型

## 条件随机场

## 关于熵
我们要搞清楚一件非常不确定的事，或是我们一无所知的事情，就需要了解大量的信息。相反，如果我们对某件事情已经有了较多的了解，那么不需要太多的信息就能把它搞清楚。所以，从这个角度来看，可以认为，信息量就等于不确定性的多少。
### 熵
$$
H(X)=-\sum_{x \in X} P(x) \log P(x)
$$

### 条件熵
$$
H(X \mid Y)=-\sum_{x \in X,y \in Y} P(x,y) \log P(x \mid y)
$$
如果H(X)>=H(X|Y)，也就是说多了Y的信息，关于X的不确定性下降了。

###  互信息
$$
H(X ; Y)= H(X) - H(X \mid Y)
$$
两件事相关性的量化度量。